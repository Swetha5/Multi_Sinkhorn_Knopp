n_gpu: 4
arch:
  type: 'TransformerPerModalityModel2'
  args:
    video_embed_dim: 4096
    text_embed_dim: 300
    davenet_v2: true
    strategy_audio_pooling: 'none'
    token_projection: 'gated'
    use_positional_emb: false
    #individual_projections: true
    fusion_params:
      embed_dim: 4096
      use_cls_token: false
      depth: 1
      num_heads: 64
      mlp_ratio: 1
      anc_len_vid: 64
      anc_len_txt: 64
      anc_len_aud: 64
      c_loss_1_1: 1.0
      c_loss_1_2: 1.0
      c_loss_1_3: 0.1
      c_loss_2_1: 1.0
      c_loss_2_2: 1.0
      c_loss_2_3: 0.1
      c_loss_3_1: 0.1
      c_loss_3_2: 0.1
      c_loss_3_3: 0.1
      c_loss_4_1: 1.0
      c_loss_4_2: 1.0
      c_loss_4_3: 0.1
      c_loss_5_1: 1.0
      c_loss_5_2: 1.0
      c_loss_5_3: 0.1
      c_loss_6_1: 0.1
      c_loss_6_2: 0.1
      c_loss_6_3: 0.1
    projection_dim: 6144
    projection: 'gated'



data_loader:
  type: FeatureDataloader
  args:
    num_workers: 32
    batch_size: 216
    shuffle: true
    drop_last: true
    dataset_name: 'HowTo100M'
    dataset_kwargs:
      flag_text_audio_misaligned: true
      csv: './data/howto/HowTo100M_1166_videopaths.txt'
      features_path: './data/howto/features'
      features_path_audio: './data/howto/audio_features'
      n_video_tokens: 12 # we use 1.5 3D-feature per second (and 1 2D-feature per second), so with 8 sec clip we get 8 x 1.5 = 12 tokens
      min_time: 8.0
      max_words: 20
      we_dim: 300
      n_clips: 10
      num_audio_STFT_frames: 768 # 1 sec of audio corresponds to 100 STFT frames, so 8 sec audio = 800 STFT frames. We use 768 to get exactly 768 / 64 = 12 tokens with davenet_v2
      caption_path: './data/howto/caption.pickle'
      word2vec_path: './data/GoogleNews-vectors-negative300.bin'

val_data_loaders:
  - type: FeatureDataloader
    args:
      num_workers: 8
      batch_size: 128
      shuffle: false
      dataset_name: 'MSRVTT'

      dataset_kwargs:
        data_path: './data/msrvtt/resnet/msrvtt_jsfusion_test.pkl'
        max_words: 20
        training: false
        n_video_tokens: 48 # we use 32 sec for evaluation, 32 x 1.5 = 48 tokens
        num_audio_STFT_frames: 3072 # we use 32 sec for evaluation (3200 STFT_frames), we use 3072 to get exactly 3072 / 64 = 48 tokens with davenet_v2
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

  - type: FeatureDataloader
    args:
      num_workers: 16
      batch_size: 128
      shuffle: false
      dataset_name: 'YouCook2'

      dataset_kwargs:
        data_path: './data/youcook/resnet/youcook_val.pkl'
        max_words: 20
        n_video_tokens: 72 # we use 48 sec for evaluation, so 48 x 1.5 = 72 tokens
        num_audio_STFT_frames: 4608 # we use 48 sec for evaluation (4800 STFT_frames), we use 4608 to get exactly 4608 / 64 = 72 tokens with davenet_v2
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

val_cls_data_loaders:
  - type: FeatureDataloader
    args:
      num_workers: 8
      batch_size: 8
      shuffle: false
      dataset_name: 'UCF'

      dataset_kwargs:
        data_path: './data/UCF101_data.pkl'
        max_words: 20
        training: false
        n_video_tokens: 48 # we use 32 sec for evaluation, 32 x 1.5 = 48 tokens
        num_audio_STFT_frames: 3072 # we use 32 sec for evaluation (3200 STFT_frames), we use 3072 to get exactly 3072 / 64 = 48 tokens with davenet_v2
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

  - type: FeatureDataloader
    args:
      num_workers: 8
      batch_size: 8
      shuffle: false
      dataset_name: 'hmdb'

      dataset_kwargs:
        data_path: './data/HMDB_data.pkl'
        max_words: 20
        n_video_tokens: 48 # we use 48 sec for evaluation, so 48 x 1.5 = 72 tokens
        num_audio_STFT_frames: 3072 # we use 48 sec for evaluation (4800 STFT_frames), we use 4608 to get exactly 4608 / 64 = 72 tokens with davenet_v2
        word2vec_path: './data/GoogleNews-vectors-negative300.bin'

optimizer:
  type: Adam
  args:
    lr: 0.00005
lr_scheduler:
  type: ExponentialLR
  args:
    gamma: 0.9

loss:
  type: CombinatorialLoss
  args:
    tv_weight: 1
    ta_weight: 0.1
    va_weight: 0.1
    t_va_weight: 0.1
    v_ta_weight: 0.1
    a_tv_weight: 0.1
    alpha_closs: 1.0
    
anc_loss:
  type: AncSimilarityLoss
  args:
    queue_len: 5500
    sk_params:
      required_properties: 0.5
      eps: 0.07
      niters: 20
      #beta_loss: 0.0
      

metrics:
- t2v_metrics
- v2t_metrics
- t2a_metrics
- a2t_metrics
- v2a_metrics
- a2v_metrics
- t2va_metrics
- va2t_metrics
- v2ta_metrics
- ta2v_metrics
- a2tv_metrics
- tv2a_metrics
- t2v+a_metrics
- v+a2t_metrics
- v2t+a_metrics
- t+a2v_metrics
- a2t+v_metrics
- t+v2a_metrics

trainer:
  epochs: 15
  mixed_precision: true
  #max_samples_per_epoch: 1000 #  for debug
  save_dir: ./output/exp_name
  log_dir: ./tb_logs/exp_name
  save_period: 20
  verbosity: 2
  monitor: 'off'
  init_val: false
  neptune: false
  ema_decay: 0.9999
